1. 从某一类pdf转txt之后，所有txt放一个文件夹（我html转的也一块放进来了），在这个文件夹中运行appendit0.py在上一级目录下的newdata文件夹中生成brio预处理的文件hello*（这个helloi就是截取第i个位置的样本），这个是可以写一个批处理脚本在所有类文件夹中自动完成的，我没写。

2. 在newdata中运行appendit.py将helloi进行再一步正则处理变为helloi_（这个可以直接在上一步的脚本里改，这一步出现的原因就是预处理不彻底还有奇怪符号，但是我只去除了一部分，不知道为什么在上一个脚本按中文韩文英文和空格过滤后，还是有一些奇怪符号qwq

3. 在与newdata同一级的目录运行shuffleit.py，将newdata中helloi_的数据按3：1：1分配到traini：validi：testi,其中因为apt数据量过大我计数每五条抽一条（awk命令统计并计算），让数据量平均一点，之后一定要用shuf命令将文件中的所有行打乱，要不训练效果奇差，这里linux命令直接解决的
4. 在与newdata同一级的目录运行try.py.这里的try.py是经过精简的bert多分类模型，好像学习率是变化的，降为0会自动提前结束训练，改进点是可以parse命令行参数 更改训练数据 然后批处理，我也懒得写了，对了，这个会保存模型，记得每次训练完要删除模型
5.  predict.py是用来预测的，预测和真实数据的对比保存在test.csv



​               